{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Analysis of the Transportation Loads by Balancing Authority\n",
    "\n",
    "This notebook analyzes the time series of transportation and total loads by Balancing Authority (BA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the top-level directory and the subdirectory where the data will be stored:\n",
    "load_data_input_dir =  '/Users/burl878/Documents/IMMM/GODEEP/Data/TELL/Production_Runs/tell_data/'\n",
    "trn_data_input_dir =  '/Users/burl878/Documents/IMMM/GODEEP/Data/Transportation/'\n",
    "data_output_dir =  '/Users/burl878/Documents/Code/code_repos/load_analysis/data/'\n",
    "image_output_dir =  '/Users/burl878/Documents/Code/code_repos/load_analysis/figures/Balancing_Authorities/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169dc070-0ab8-4833-b6a0-589869ebf64e",
   "metadata": {},
   "source": [
    "## Merge the Ouptut Files for 2035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ccf33-f406-4fb7-9e16-32e32e2225dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read in the load and transportation data for a given BA:\n",
    "def merge_load_trn_data(ba: str, scenario: str, load_data_input_dir: str, trn_data_input_dir: str):\n",
    "    \n",
    "    # Load in the raw data file:\n",
    "    ldv_df = pd.read_csv(os.path.join(trn_data_input_dir, r'LDV', scenario, r'rcp45cooler', (ba + '_hourly_LDV_load_' + scenario + '_rcp45cooler_2035.csv')), index_col=None, header=0)\n",
    "    \n",
    "    # Convert the timestamp into a datetime variable:\n",
    "    ldv_df['Date'] = pd.to_datetime(ldv_df['time'])\n",
    "\n",
    "    # Use datetime string to get the year, month, day, and hour:\n",
    "    ldv_df['Year'] = ldv_df['Date'].dt.strftime('%Y').astype(int)\n",
    "    ldv_df['Month'] = ldv_df['Date'].dt.strftime('%m').astype(int)\n",
    "    ldv_df['Day'] = ldv_df['Date'].dt.strftime('%d').astype(int)\n",
    "    ldv_df['Hour'] = ldv_df['Date'].dt.strftime('%H').astype(int)\n",
    "\n",
    "    # Rename a the load variable:\n",
    "    ldv_df.rename(columns={'load_MWh': 'LDV_Load_MWh'}, inplace=True)\n",
    "\n",
    "    # Subset to only the columns we need:\n",
    "    ldv_df = ldv_df[['Year', 'Month', 'Day', 'Hour', 'LDV_Load_MWh']]\n",
    "    \n",
    "    # Load in the raw data file:\n",
    "    if scenario == 'BAU':\n",
    "       mdv_df = pd.read_csv(os.path.join(trn_data_input_dir, r'MHDV', scenario, ('mdv_BAU_' + ba + '_profile_2035.csv')), index_col=None, header=0)\n",
    "    if scenario == 'NetZero':\n",
    "       mdv_df = pd.read_csv(os.path.join(trn_data_input_dir, r'MHDV', scenario, ('mdv_NZ_' + ba + '_profile_2035.csv')), index_col=None, header=0)\n",
    "    \n",
    "    # Convert the timestamp into a datetime variable:\n",
    "    mdv_df['Date'] = pd.to_datetime(mdv_df['time'])\n",
    "\n",
    "    # Use datetime string to get the year, month, day, and hour:\n",
    "    mdv_df['Year'] = mdv_df['Date'].dt.strftime('%Y').astype(int)\n",
    "    mdv_df['Month'] = mdv_df['Date'].dt.strftime('%m').astype(int)\n",
    "    mdv_df['Day'] = mdv_df['Date'].dt.strftime('%d').astype(int)\n",
    "    mdv_df['Hour'] = mdv_df['Date'].dt.strftime('%H').astype(int)\n",
    "\n",
    "    # Rename a the load variable:\n",
    "    mdv_df.rename(columns={'MW': 'MDV_Load_MWh'}, inplace=True)\n",
    "\n",
    "    # Subset to only the columns we need:\n",
    "    mdv_df = mdv_df[['Year', 'Month', 'Day', 'Hour', 'MDV_Load_MWh']]\n",
    "    \n",
    "    # Load in the raw data file:\n",
    "    if scenario == 'BAU':\n",
    "       hdv_df = pd.read_csv(os.path.join(trn_data_input_dir, r'MHDV', scenario, ('hdv_BAU_' + ba + '_profile_2035.csv')), index_col=None, header=0)\n",
    "    if scenario == 'NetZero':\n",
    "       hdv_df = pd.read_csv(os.path.join(trn_data_input_dir, r'MHDV', scenario, ('hdv_NZ_' + ba + '_profile_2035.csv')), index_col=None, header=0)\n",
    "    \n",
    "    # Convert the timestamp into a datetime variable:\n",
    "    hdv_df['Date'] = pd.to_datetime(hdv_df['time'])\n",
    "\n",
    "    # Use datetime string to get the year, month, day, and hour:\n",
    "    hdv_df['Year'] = hdv_df['Date'].dt.strftime('%Y').astype(int)\n",
    "    hdv_df['Month'] = hdv_df['Date'].dt.strftime('%m').astype(int)\n",
    "    hdv_df['Day'] = hdv_df['Date'].dt.strftime('%d').astype(int)\n",
    "    hdv_df['Hour'] = hdv_df['Date'].dt.strftime('%H').astype(int)\n",
    "\n",
    "    # Rename a the load variable:\n",
    "    hdv_df.rename(columns={'MW': 'HDV_Load_MWh'}, inplace=True)\n",
    "\n",
    "    # Subset to only the columns we need:\n",
    "    hdv_df = hdv_df[['Year', 'Month', 'Day', 'Hour', 'HDV_Load_MWh']]\n",
    "    \n",
    "    # Read in the TELL BA output file for that year and scenario:\n",
    "    if scenario == 'BAU':\n",
    "       tell_df = pd.read_csv(load_data_input_dir + 'outputs/tell_output/BAU_Climate/2035/TELL_Balancing_Authority_Hourly_Load_Data_2035_Scaled_2035.csv')\n",
    "    if scenario == 'NetZero':\n",
    "       tell_df = pd.read_csv(load_data_input_dir + 'outputs/tell_output/NetZeroNoCCS_Climate/2035/TELL_Balancing_Authority_Hourly_Load_Data_2035_Scaled_2035.csv')\n",
    "    \n",
    "    # Subset to just the data for the state being processed:\n",
    "    tell_df = tell_df[tell_df['BA_Code'] == ba].copy()\n",
    "    \n",
    "    # Convert the timestamp into a datetime variable:\n",
    "    tell_df['Date'] = pd.to_datetime(tell_df['Time_UTC'])\n",
    "\n",
    "    # Use datetime string to get the year, month, day, and hour:\n",
    "    tell_df['Year'] = tell_df['Date'].dt.strftime('%Y').astype(int)\n",
    "    tell_df['Month'] = tell_df['Date'].dt.strftime('%m').astype(int)\n",
    "    tell_df['Day'] = tell_df['Date'].dt.strftime('%d').astype(int)\n",
    "    tell_df['Hour'] = tell_df['Date'].dt.strftime('%H').astype(int)\n",
    "\n",
    "    # Rename a the load variable:\n",
    "    tell_df.rename(columns={'Scaled_TELL_BA_Load_MWh': 'TELL_Load_MWh'}, inplace=True)\n",
    "\n",
    "    # Subset to only the columns we need:\n",
    "    tell_df = tell_df[['Time_UTC', 'Year', 'Month', 'Day', 'Hour', 'TELL_Load_MWh']]\n",
    "    \n",
    "    # Merge the dataframes together based on common year, month, and day combinations:\n",
    "    merged_df = pd.merge(tell_df, ldv_df, how='left', on=['Year', 'Month', 'Day', 'Hour'])\n",
    "    merged_df = pd.merge(merged_df, mdv_df, how='left', on=['Year', 'Month', 'Day', 'Hour'])\n",
    "    merged_df = pd.merge(merged_df, hdv_df, how='left', on=['Year', 'Month', 'Day', 'Hour'])\n",
    "    \n",
    "    # Compute the total transportation load and round off the values to make the output file more readable:\n",
    "    merged_df['TRN_Load_MWh'] = (merged_df['LDV_Load_MWh'] + merged_df['MDV_Load_MWh'] + merged_df['HDV_Load_MWh']).round(2)\n",
    "    merged_df['LDV_Load_MWh'] = merged_df['LDV_Load_MWh'].round(2)\n",
    "    merged_df['MDV_Load_MWh'] = merged_df['MDV_Load_MWh'].round(2)\n",
    "    merged_df['HDV_Load_MWh'] = merged_df['HDV_Load_MWh'].round(2)\n",
    "    \n",
    "    # Calculate the load ratio (transportation load divided by total load):\n",
    "    merged_df['Load_Ratio'] = (merged_df['TRN_Load_MWh']/merged_df['TELL_Load_MWh']).round(3)\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abe13f-ec5f-4ee2-919c-e53a3037239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = merge_load_trn_data(ba = 'AZPS', \n",
    "                        scenario = 'NetZero', \n",
    "                        load_data_input_dir = load_data_input_dir, \n",
    "                        trn_data_input_dir = trn_data_input_dir)\n",
    "\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702ad29-cc94-435c-9aac-25b1524e47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot the comparison between the TELL and transportation loads for a given BA:\n",
    "def plot_data_comparison(ba_to_plot: str, scenario_to_plot: str, load_data_input_dir: str, trn_data_input_dir: str, image_output_dir: str, save_images=False):\n",
    "    \n",
    "    # Merge the required data using the function created above:\n",
    "    merged_df = merge_load_trn_data(ba = ba_to_plot, \n",
    "                                    scenario = scenario_to_plot, \n",
    "                                    load_data_input_dir = load_data_input_dir, \n",
    "                                    trn_data_input_dir = trn_data_input_dir)\n",
    "    \n",
    "    # Compute the maximum load to be used in plotting:\n",
    "    max_load = merged_df[['TRN_Load_MWh', 'TELL_Load_MWh']].max(axis=0).max(axis=0)\n",
    "    \n",
    "    # Initiate an empty dataframe to store the mean diurnal cycle results:\n",
    "    mean_tell_load_df = pd.DataFrame()\n",
    "    mean_trn_load_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop over the seasons and compute the mean diurnal cycle for each season:\n",
    "    for season in range(4):\n",
    "        months = pd.DataFrame()\n",
    "        if season == 0: # Dec-Jan-Feb\n",
    "            months.loc[1,1] = 12; months.loc[1,2] = 1; months.loc[1,3] = 2;\n",
    "        if season == 1: # Mar-Apr-May\n",
    "            months.loc[1,1] = 3; months.loc[1,2] = 4; months.loc[1,3] = 5;\n",
    "        if season == 2: # Jun-Jul-Aug\n",
    "            months.loc[1,1] = 6; months.loc[1,2] = 7; months.loc[1,3] = 8;\n",
    "        if season == 3: # Sep-Oct_Nov\n",
    "            months.loc[1,1] = 9; months.loc[1,2] = 10; months.loc[1,3] = 11;\n",
    "            \n",
    "        # Subset the data to the three months in a given season:\n",
    "        month_subset_df = merged_df.loc[(merged_df['Month'] == months.loc[1,1]) | (merged_df['Month'] == months.loc[1,2]) | (merged_df['Month'] == months.loc[1,3])]\n",
    "        \n",
    "        # Loop over the hours of a day and subset the data to only that hour:\n",
    "        for hour in range(24):\n",
    "            # Subset the seasonal data to only that hour:\n",
    "            hour_subset_df = month_subset_df.loc[(month_subset_df['Hour'] == hour)]\n",
    "            \n",
    "            # Compute the mean total and mean transportation load for that season and hour combination:\n",
    "            mean_tell_load_df.loc[season,hour] = hour_subset_df['TELL_Load_MWh'].mean()\n",
    "            mean_trn_load_df.loc[season,hour] = hour_subset_df['TRN_Load_MWh'].mean()\n",
    "            \n",
    "            # Clean up the dataframes we no longer need:\n",
    "            del hour_subset_df\n",
    "    \n",
    "        # Clean up the dataframes we no longer need:\n",
    "        del months, month_subset_df\n",
    "    \n",
    "    # Find the index of the maximum load ratio throughout the year:\n",
    "    index = merged_df['Load_Ratio'].idxmax(axis=0)\n",
    "    if index > 84:\n",
    "       start = (index -84)\n",
    "    else:\n",
    "       start = 0\n",
    "\n",
    "    if index < (len(merged_df)-84):\n",
    "       end = (index + 84)\n",
    "    else:\n",
    "       end = len(merged_df)\n",
    "\n",
    "    # Create a subset of just the week around the maximum load ratio:\n",
    "    peak_df = merged_df[start:end]\n",
    "    \n",
    "    \n",
    "    # Make the plot:\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    \n",
    "    plt.subplot(321)\n",
    "    plt.scatter(merged_df['TELL_Load_MWh'], merged_df['TRN_Load_MWh'], s=15, c='blue')\n",
    "    plt.plot([0, max_load], [0, max_load], color='k', linestyle='-', linewidth=2)\n",
    "    plt.plot([0, max_load], [0, (0.9*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.8*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.7*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.6*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.5*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.4*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.3*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.2*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, max_load], [0, (0.1*max_load)], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.xlim([0, max_load])\n",
    "    plt.ylim([0, max_load])\n",
    "    plt.xlabel('Total Non-Transportation Load [MWh]')\n",
    "    plt.ylabel('Total Transportation Load [MWh]')\n",
    "    plt.title('2035 ' + scenario_to_plot + ' Transportation vs Non-Transportation Load in ' + ba_to_plot)\n",
    "    \n",
    "    plt.subplot(322)\n",
    "    plt.hist(merged_df['Load_Ratio'], bins = (pd.Series(np.arange(0,2,0.05))))\n",
    "    plt.xlim([0, 2])\n",
    "    plt.xlabel('Load Ratio [Transportation/Non-Transportation]')\n",
    "    plt.ylabel('Hours')\n",
    "    plt.title('2035 ' + scenario_to_plot + ' Load Ratios in ' + ba_to_plot + ': Min = ' + str(merged_df['Load_Ratio'].min(axis=0).round(3)) + ', Max = ' + str(merged_df['Load_Ratio'].max(axis=0).round(3)))\n",
    "    \n",
    "    plt.subplot(312)\n",
    "    plt.plot(np.arange(0,24,1), mean_tell_load_df.loc[0,:], color = 'b', linewidth = 3, linestyle = '-', label = 'TELL: Dec-Jan-Feb')\n",
    "    plt.plot(np.arange(0,24,1), mean_trn_load_df.loc[0,:],  color = 'b', linewidth = 3, linestyle = ':', label = 'LDV + MDV + HDV: Dec-Jan-Feb')\n",
    "    plt.plot(np.arange(0,24,1), mean_tell_load_df.loc[1,:], color = 'g', linewidth = 3, linestyle = '-', label = 'TELL: Mar-Apr-May')\n",
    "    plt.plot(np.arange(0,24,1), mean_trn_load_df.loc[1,:],  color = 'g', linewidth = 3, linestyle = ':', label = 'LDV + MDV + HDV: Mar-Apr-May')\n",
    "    plt.plot(np.arange(0,24,1), mean_tell_load_df.loc[2,:], color = 'r', linewidth = 3, linestyle = '-', label = 'TELL: Jun-Jul-Aug')\n",
    "    plt.plot(np.arange(0,24,1), mean_trn_load_df.loc[2,:],  color = 'r', linewidth = 3, linestyle = ':', label = 'LDV + MDV + HDV: Jun-Jul-Aug')\n",
    "    plt.plot(np.arange(0,24,1), mean_tell_load_df.loc[3,:], color = 'orange', linewidth = 3, linestyle = '-', label = 'TELL: Sep-Oct-Nov')\n",
    "    plt.plot(np.arange(0,24,1), mean_trn_load_df.loc[3,:],  color = 'orange', linewidth = 3, linestyle = ':', label = 'LDV + MDV + HDV: Sep-Oct-Nov')\n",
    "    plt.legend()\n",
    "    plt.xlim([0, 23])\n",
    "    plt.xlabel('Hour of the Day [UTC]')\n",
    "    plt.ylabel('Mean Load [MWh]')\n",
    "    plt.title('Mean Seasonal Diurnal Cycles')\n",
    "        \n",
    "    plt.subplot(313)\n",
    "    plt.plot(peak_df['Time_UTC'], peak_df['TELL_Load_MWh'], 'k', linewidth=3, label='Total Non-Transportation Load')\n",
    "    plt.plot(peak_df['Time_UTC'], peak_df['TRN_Load_MWh'], 'g', linewidth=3, label='Total Transportation Load')\n",
    "    plt.plot(peak_df['Time_UTC'], peak_df['LDV_Load_MWh'], 'b', linewidth=3, label='LDV Load')\n",
    "    plt.plot(peak_df['Time_UTC'], peak_df['MDV_Load_MWh'], 'c', linewidth=3, label='MDV Load')\n",
    "    plt.plot(peak_df['Time_UTC'], peak_df['HDV_Load_MWh'], 'm', linewidth=3, label='HDV Load')\n",
    "    plt.xlim(peak_df['Time_UTC'].dropna().min(), peak_df['Time_UTC'].dropna().max())\n",
    "    plt.xticks([])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Demand [MWh]')\n",
    "    plt.title('Week of the Highest Load Ratio: ' + peak_df['Time_UTC'].dropna().min() + ' to ' + peak_df['Time_UTC'].dropna().max())\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       filename = (ba_to_plot + '_' + scenario_to_plot + '_Transportation_Comparison.png')\n",
    "       plt.savefig(os.path.join(image_output_dir, filename), dpi=75, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5457f7-6e87-45f1-a6db-ecda36cfb680",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_comparison(ba_to_plot = 'WACM',\n",
    "                     scenario_to_plot = 'BAU',\n",
    "                     load_data_input_dir = load_data_input_dir, \n",
    "                     trn_data_input_dir = trn_data_input_dir,\n",
    "                     image_output_dir = image_output_dir,\n",
    "                     save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7bd7f-506c-43d2-ba27-7eec2fc6a574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
